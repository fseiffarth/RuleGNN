datasets: #TODO: repair broken NCI109
  # real-world datasets
  - {name: "NCI1", data: "Reproduce_RuleGNN/Data/TUDatasets/", validation_folds: 10, experiment_config_file: "Reproduce_RuleGNN/Configs/config_NCI1.yml", type: "TUDataset"}
#  - {name: "NCI109", data: "Reproduce_RuleGNN/Data/TUDatasets/", validation_folds: 10, experiment_config_file: "Reproduce_RuleGNN/Configs/config_NCI1.yml", type: "TUDataset"}
  - {name: "IMDB-BINARY", data: "Reproduce_RuleGNN/Data/TUDatasets/", validation_folds: 10, experiment_config_file: "Reproduce_RuleGNN/Configs/config_IMDB.yml", type: "TUDataset"}
  - {name: "IMDB-MULTI", data: "Reproduce_RuleGNN/Data/TUDatasets/", validation_folds: 10, experiment_config_file: "Reproduce_RuleGNN/Configs/config_IMDB.yml", type: "TUDataset"}

paths:
  # all the paths are relative to the PYTHONPATH path, can be also defined dataset-wise in the experiment_config_file
  properties:
    "Reproduce_RuleGNN/Data/Properties/" # Precomputed properties will be loaded from this folder
  labels:
    "Reproduce_RuleGNN/Data/Labels/" # Path to the folder containing the labels
  splits:
    "Reproduce_RuleGNN/Data/SplitsSimple/" # Path to the folder containing the data splits
  results:
    "Reproduce_RuleGNN/ResultsSOTA/" # Results will be saved in this folder


early_stopping:
  enabled:
    False
  patience:
    25

weight_initialization: { convolution: { type: 'lower_upper' },
                         convolution_bias: { type: 'constant', value: 0.0 },
                         aggregation: { type: 'lower_upper' },
                         aggregation_bias: { type: 'constant', value: 0.0 }}

# input_features: determine how the input features should be transformed, the following options show some examples
#  - {name: constant, value: 1.0}, use a constant value as input feature
#  - {name: node_labels, transformation: normalize}, use node labels and normalize them between -1 and 1
#  - {name: node_labels, transformation: normalize_positive}, use node labels and normalize them between 0 and 1
#  - {name: node_labels, transformation: unit_circle, features_as_channels: True}, use node labels mapped to the 2D unit circle, use features as channels
#  - {name: node_labels, transformation: one_hot, features_as_channels: True}, use node labels and transform them to one-hot encoding
#  - {name: node_features, features_as_channels: True}, use node features as input, use features as channels
#  - {name: all, features_as_channels: True}, use node labels and node features as input, use features as channels
input_features: { name: node_labels, transformation: normalize }