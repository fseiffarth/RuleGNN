paths:
  # all the paths are relative to the PYTHONPATH path
  data:
    "Reproduce_RuleGNN/Data/SyntheticDatasets/" # Path to the folder containing the graph data
  properties:
    "Reproduce_RuleGNN/Data/Properties/" # Precomputed properties will be loaded from this folder
  labels:
    "Reproduce_RuleGNN/Data/Labels/" # Path to the folder containing the labels
  results:
    "Reproduce_RuleGNN/Results/" # Results will be saved in this folder
  splits:
    "Reproduce_RuleGNN/Data/Splits/" # Path to the folder containing the data splits
device:
  cpu
mode:
  experiments # if debug printing and plotting options are enabled, for the experiments mode should be 'experiments'
batch_size:
  - 128
learning_rate:
  - 0.1
epochs:
  - 200
scheduler:
  False
dropout:
  - 0.0
optimizer:
  - Adam
loss:
  - CrossEntropyLoss
early_stopping:
  enabled:
    False
  patience:
    25
networks:
  # mixed models
  - - { layer_type: subgraph, id: 0, properties: { name: distances, values: [ 3 ] }}
    - { layer_type: wl, wl_iterations: 0}

# if subgraph labels are used the corresponding list of subgraphs should be provided here:
subgraphs:
  - "[nx.cycle_graph(4), nx.cycle_graph(5)]"




use_features: # if True uses normlized node labels as input features, if False uses 1-vector as input features
  True
use_attributes: # if True uses node attributes instead of node labels
  False
random_variation: # if True adds random variation to the input features
  False
load_splits: # if True loads precomputed data splits (use False only for new datasets)
  True

# data options
balance_training:
  False

# Additional options for analysis only possible in debug mode
additional_options:
  draw: # draw the accuracy and loss during training
    True
  save_weights: # save the weights of the model
    False
  save_prediction_values:
    True
  plot_graphs: # Plot all graphs in the dataset
    False
  print_results: # Print accuracy and loss in the console
    True

best_model:
  False

precision:
    double