# datasets: list of datasets to be used for the experiment
# -name: "DHFR", name of the dataset (if type is TUDataset, the name can be any of the datasets from
# -validation_folds: 10, number of validation folds
# -experiment_config_file: path to the experiment configuration file
# -type: type of the dataset, options: [TUDataset, generate_from_function]
# -generate_function: if type is generate_from_function, the name of the function to generate the dataset from src/utils/SyntheticGraphs.py
# -generate_function_args: if type is generate_from_function, the arguments for the generate function as a dictionary
datasets:
  - {name: "DHFR", validation_folds: 10, experiment_config_file: "Examples/TUExample/Configs/config_experiment.yml", type: "TUDataset"}

# paths: paths to the data, properties, labels, results and splits
paths:
  # Path to the folder containing the graph data
  data: "Examples/TUExample/Data/"
  # Precomputed properties will be saved and loaded from this folder
  properties: "Examples/TUExample/Data/Properties/"
  # Path to the folder containing the labels
  labels: "Examples/TUExample/Data/Labels/"
  # Results will be saved in this folder
  results: "Examples/TUExample/Results/"
  # Path to the folder containing the data splits
  splits: "Examples/TUExample/Data/Splits/"

# network options
# bias: Turn on or off the bias in all layers
bias: True

# convolution_grad: Turn on or off learning for the convolutional layers
convolution_grad: True

# aggregation_grad: Turn on or off learning for the aggregation layer
aggregation_grad: True

# activation: activation function for the convolutional layers
activation: 'tanh'

# output_activation: activation function for the output layer
output_activation: 'tanh'

# rule_occurrence_threshold: threshold for the rule occurrence, determines how often a rule has to be present to be used in the network
# -type: [graph, total], graph: the rule has to be present in a graph, total: the rule has to be present in the whole dataset
# -threshold: the threshold for the rule occurrence at least this many times
rule_occurrence_threshold: { type: 'graph', threshold: 1 }

# weight initialization: weight initialization for the network (TODO)
# - convolution: weight initialization for the convolutional layers
# - convolution_bias: weight initialization for the convolutional bias
# - aggregation: weight initialization for the aggregation layer
# - aggregation_bias: weight initialization for the aggregation bias
# keys:
#     - type: [uniform, normal, constant, lower_upper], uniform: uniform distribution, normal: normal distribution, constant: constant value, lower_upper: uniform distribution with lower and upper bound from the number of weights
#     - minval: minimum value for the uniform distribution
#     - maxval: maximum value for the uniform distribution
#     - value: constant value for the constant distribution
#     - mean for the normal distribution
#     - std: variance for the normal distribution
weight_initialization: { convolution: { type: 'constant', value: 0.001 },
                         convolution_bias: { type: 'constant', value: 0.001 },
                         aggregation: { type: 'constant', value: 0.001 },
                         aggregation_bias: { type: 'constant', value: 0.001 }}


# input_features: determine how the input features should be transformed, the following options show some examples
# keys:
#  - name: [constant, node_labels, node_features, all], the type of input features
#  - transformation: [normalize, normalize_positive, unit_circle, one_hot], the transformation of the input features
#  - features_as_channels: True, use the features as channels
#  - value: constant value for the constant input features
#  - random_variation: add random variation to the input features
# examples:
#  - {name: constant, value: 1.0}, use a constant value as input feature
#  - {name: node_labels, transformation: normalize}, use node labels and normalize them between -1 and 1
#  - {name: node_labels, transformation: normalize_positive}, use node labels and normalize them between 0 and 1
#  - {name: node_labels, transformation: unit_circle, features_as_channels: True}, use node labels mapped to the 2D unit circle, use features as channels
#  - {name: node_labels, transformation: one_hot, features_as_channels: True}, use node labels and transform them to one-hot encoding
#  - {name: node_features, features_as_channels: True}, use node features as inpu, use features as channels
#  - {name: all, features_as_channels: True}, use node labels and node features as input, use features as channels
input_features: { name: constant, value: 1.0, random_variation: { mean: 0.0, variance: 0.5 } }

# num_workers: number of workers used
num_workers: 10




